"""
Functions for network matched-filter detection of seismic data.

Designed to cross-correlate templates generated by template_gen function
with data and output the detections.

:copyright:
    EQcorrscan developers.

:license:
    GNU Lesser General Public License, Version 3
    (https://www.gnu.org/copyleft/lesser.html)
"""
import copy
import getpass
import glob
import os
import pickle
import shutil
import tarfile
import tempfile
import time
import traceback
import logging
import numpy as np

from collections import defaultdict
from typing import List, Union
from timeit import default_timer

from concurrent.futures import ThreadPoolExecutor
from multiprocessing import Process, JoinableQueue, cpu_count
from queue import Empty

from obspy import Catalog, Stream, read, read_events
from obspy.core.event import Comment, CreationInfo

from eqcorrscan.core.match_filter.template import (
    Template, quick_group_templates, group_templates_by_seedid)
from eqcorrscan.core.match_filter.detection import Detection
from eqcorrscan.core.match_filter.party import Party
from eqcorrscan.core.match_filter.family import Family
from eqcorrscan.core.match_filter.helpers import (
    _safemembers, _par_read, get_waveform_client, _spike_test)
from eqcorrscan.core.match_filter.matched_filter import MatchFilterError
from eqcorrscan.core import template_gen

from eqcorrscan.utils.correlate import (
    get_stream_xcorr, _get_array_dicts, _fmf_stabilisation, _stabalised_fmf,
    _fmf_reshape, fftw_multi_normxcorr, _zero_invalid_correlation_sums,
    _set_inner_outer_threading)
from eqcorrscan.utils.pre_processing import (
    _check_daylong, _quick_copy_stream, _prep_data_for_correlation,
    _group_process)
from eqcorrscan.utils.findpeaks import multi_find_peaks
from eqcorrscan.utils.plotting import _match_filter_plot

Logger = logging.getLogger(__name__)


class Tribe(object):
    """
    Holder for multiple templates.

    :type templates: List of Template
    :param templates: The templates within the Tribe.
    """
    _timeout = 1

    def __init__(self, templates=None):
        self.templates = []
        if isinstance(templates, Template):
            templates = [templates]
        if templates:
            self.templates.extend(templates)
        # Managers for Processes and Queues to be killed on errors
        self._processes = dict()
        self._queues = dict()

    def __repr__(self):
        """
        Print information about the tribe.

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='a')])
        >>> print(tribe)
        Tribe of 1 templates
        """
        return 'Tribe of %i templates' % self.__len__()

    def __add__(self, other):
        """
        Add two Tribes or a Tribe and a Template together. '+'

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='a')])
        >>> tribe_ab = tribe + Tribe(templates=[Template(name='b')])
        >>> print(tribe_ab)
        Tribe of 2 templates
        >>> tribe_abc = tribe_ab + Template(name='c')
        >>> print(tribe_abc)
        Tribe of 3 templates
        """
        return self.copy().__iadd__(other)

    def __iadd__(self, other):
        """
        Add in place: '+='

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='a')])
        >>> tribe += Tribe(templates=[Template(name='b')])
        >>> print(tribe)
        Tribe of 2 templates
        >>> tribe += Template(name='c')
        >>> print(tribe)
        Tribe of 3 templates
        """
        if isinstance(other, Tribe):
            self.templates += other.templates
        elif isinstance(other, Template):
            self.templates.append(other)
        else:
            raise TypeError('Must be either Template or Tribe')
        return self

    def __eq__(self, other):
        """
        Test for equality. Rich comparison operator '=='

        .. rubric:: Example

        >>> tribe_a = Tribe(templates=[Template(name='a')])
        >>> tribe_b = Tribe(templates=[Template(name='b')])
        >>> tribe_a == tribe_b
        False
        >>> tribe_a == tribe_a
        True
        """
        if self.sort().templates != other.sort().templates:
            return False
        return True

    def __ne__(self, other):
        """
        Test for inequality. Rich comparison operator '!='

        .. rubric:: Example

        >>> tribe_a = Tribe(templates=[Template(name='a')])
        >>> tribe_b = Tribe(templates=[Template(name='b')])
        >>> tribe_a != tribe_b
        True
        >>> tribe_a != tribe_a
        False
        """
        return not self.__eq__(other)

    def __len__(self):
        """
        Number of Templates in Tribe. len(tribe)

        .. rubric:: Example

        >>> tribe_a = Tribe(templates=[Template(name='a')])
        >>> len(tribe_a)
        1
        """
        return len(self.templates)

    def __iter__(self):
        """
        Iterator for the Tribe.
        """
        return list(self.templates).__iter__()

    def __getitem__(self, index):
        """
        Support slicing to get Templates from Tribe.

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='a'), Template(name='b'),
        ...                          Template(name='c')])
        >>> tribe[1] # doctest: +NORMALIZE_WHITESPACE
        Template b:
         0 channels;
         lowcut: None Hz;
         highcut: None Hz;
         sampling rate None Hz;
         filter order: None;
         process length: None s
        >>> tribe[0:2]
        Tribe of 2 templates
        """
        if isinstance(index, slice):
            return self.__class__(templates=self.templates.__getitem__(index))
        elif isinstance(index, int):
            return self.templates.__getitem__(index)
        else:
            _index = [i for i, t in enumerate(self.templates)
                      if t.name == index]
            try:
                return self.templates.__getitem__(_index[0])
            except IndexError:
                Logger.warning('Template: %s not in tribe' % index)
                return []

    def sort(self):
        """
        Sort the tribe, sorts by template name.

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='c'), Template(name='b'),
        ...                          Template(name='a')])
        >>> tribe.sort()
        Tribe of 3 templates
        >>> tribe[0] # doctest: +NORMALIZE_WHITESPACE
        Template a:
         0 channels;
         lowcut: None Hz;
         highcut: None Hz;
         sampling rate None Hz;
         filter order: None;
         process length: None s
        """
        self.templates = sorted(self.templates, key=lambda x: x.name)
        return self

    def select(self, template_name):
        """
        Select a particular template from the tribe.

        :type template_name: str
        :param template_name: Template name to look-up
        :return: Template

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='c'), Template(name='b'),
        ...                          Template(name='a')])
        >>> tribe.select('b') # doctest: +NORMALIZE_WHITESPACE
        Template b:
         0 channels;
         lowcut: None Hz;
         highcut: None Hz;
         sampling rate None Hz;
         filter order: None;
         process length: None s
        """
        return [t for t in self.templates if t.name == template_name][0]

    def remove(self, template):
        """
        Remove a template from the tribe.

        :type template: :class:`eqcorrscan.core.match_filter.Template`
        :param template: Template to remove from tribe

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='c'), Template(name='b'),
        ...                          Template(name='a')])
        >>> tribe.remove(tribe.templates[0])
        Tribe of 2 templates
        """
        self.templates = [t for t in self.templates if t != template]
        return self

    def copy(self):
        """
        Copy the Tribe.

        .. rubric:: Example

        >>> tribe_a = Tribe(templates=[Template(name='a')])
        >>> tribe_b = tribe_a.copy()
        >>> tribe_a == tribe_b
        True
        """
        # We can't copy processes, so we need to just copy the templates
        other = Tribe(copy.deepcopy(self.templates))
        return other

    def write(self, filename, compress=True, catalog_format="QUAKEML"):
        """
        Write the tribe to a file using tar archive formatting.

        :type filename: str
        :param filename:
            Filename to write to, if it exists it will be appended to.
        :type compress: bool
        :param compress:
            Whether to compress the tar archive or not, if False then will
            just be files in a folder.
        :type catalog_format: str
        :param catalog_format:
            What format to write the detection-catalog with. Only Nordic,
            SC3ML, QUAKEML are supported. Note that not all information is
            written for all formats (QUAKEML is the most complete, but is
            slow for IO).

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='c', st=read())])
        >>> tribe.write('test_tribe')
        Tribe of 1 templates
        """
        from eqcorrscan.core.match_filter import CAT_EXT_MAP

        if catalog_format not in CAT_EXT_MAP.keys():
            raise TypeError("{0} is not supported".format(catalog_format))
        dirname, ext = os.path.splitext(filename)
        if not os.path.isdir(dirname):
            os.makedirs(dirname)
        self._par_write(dirname)
        tribe_cat = Catalog()
        for t in self.templates:
            if t.event is not None:
                # Check that the name in the comment matches the template name
                for comment in t.event.comments:
                    if not comment.text:
                        comment.text = "eqcorrscan_template_{0}".format(t.name)
                    elif comment.text.startswith("eqcorrscan_template_"):
                        comment.text = "eqcorrscan_template_{0}".format(t.name)
                tribe_cat.append(t.event)
        if len(tribe_cat) > 0:
            tribe_cat.write(
                os.path.join(dirname, 'tribe_cat.{0}'.format(
                    CAT_EXT_MAP[catalog_format])), format=catalog_format)
        for template in self.templates:
            template.st.write(
                os.path.join(dirname, '{0}.ms'.format(template.name)),
                format='MSEED')
        if compress:
            if not filename.endswith(".tgz"):
                Logger.info("Appending '.tgz' to filename.")
                filename += ".tgz"
            with tarfile.open(filename, "w:gz") as tar:
                tar.add(dirname, arcname=os.path.basename(dirname))
            shutil.rmtree(dirname)
        return self

    def _par_write(self, dirname):
        """
        Internal write function to write a formatted parameter file.

        :type dirname: str
        :param dirname: Directory to write the parameter file to.
        """
        filename = dirname + '/' + 'template_parameters.csv'
        with open(filename, 'w') as parfile:
            for template in self.templates:
                for key in template.__dict__.keys():
                    if key not in ['st', 'event']:
                        parfile.write(key + ': ' +
                                      str(template.__dict__[key]) + ', ')
                parfile.write('\n')
        return self

    def read(self, filename):
        """
        Read a tribe of templates from a tar formatted file.

        :type filename: str
        :param filename: File to read templates from.

        .. rubric:: Example

        >>> tribe = Tribe(templates=[Template(name='c', st=read())])
        >>> tribe.write('test_tribe')
        Tribe of 1 templates
        >>> tribe_back = Tribe().read('test_tribe.tgz')
        >>> tribe_back == tribe
        True
        """
        if filename.endswith(".pkl"):
            with open(filename, "rb") as f:
                self.__iadd__(pickle.load(f))
            return self
        with tarfile.open(filename, "r:*") as arc:
            temp_dir = tempfile.mkdtemp()
            arc.extractall(path=temp_dir, members=_safemembers(arc))
            tribe_dir = glob.glob(temp_dir + os.sep + '*')[0]
            self._read_from_folder(dirname=tribe_dir)
        shutil.rmtree(temp_dir)
        return self

    def _read_from_folder(self, dirname):
        """
        Internal folder reader.

        :type dirname: str
        :param dirname: Folder to read from.
        """
        templates = _par_read(dirname=dirname, compressed=False)
        t_files = glob.glob(dirname + os.sep + '*.ms')
        tribe_cat_file = glob.glob(os.path.join(dirname, "tribe_cat.*"))
        if len(tribe_cat_file) != 0:
            tribe_cat = read_events(tribe_cat_file[0])
        else:
            tribe_cat = Catalog()
        previous_template_names = [t.name for t in self.templates]
        for template in templates:
            if template.name in previous_template_names:
                # Don't read in for templates that we already have.
                continue
            for event in tribe_cat:
                for comment in event.comments:
                    if comment.text == 'eqcorrscan_template_' + template.name:
                        template.event = event
            t_file = [t for t in t_files
                      if t.split(os.sep)[-1] == template.name + '.ms']
            if len(t_file) == 0:
                Logger.error('No waveform for template: ' + template.name)
                templates.remove(template)
                continue
            elif len(t_file) > 1:
                Logger.warning('Multiple waveforms found, using: ' + t_file[0])
            template.st = read(t_file[0])
        self.templates.extend(templates)
        return

    def cluster(self, method, **kwargs):
        """
        Cluster the tribe.

        Cluster templates within a tribe: returns multiple tribes each of
        which could be stacked.

        :type method: str
        :param method:
            Method of stacking, see :mod:`eqcorrscan.utils.clustering`

        :return: List of tribes.

        .. rubric:: Example


        """
        from eqcorrscan.utils import clustering
        tribes = []
        func = getattr(clustering, method)
        if method in ['space_cluster', 'space_time_cluster']:
            cat = Catalog([t.event for t in self.templates])
            groups = func(cat, **kwargs)
            for group in groups:
                new_tribe = Tribe()
                for event in group:
                    new_tribe.templates.extend([t for t in self.templates
                                                if t.event == event])
                tribes.append(new_tribe)
        return tribes

    def _close_processes(self, processes: dict = None):
        processes = processes or self._processes
        for p_name, p in processes.items():
            try:
                Logger.info(f"Joining {p_name}")
                p.join(timeout=self._timeout)
            except Exception as e:
                Logger.error(f"Failed to join due to {e}: terminating")
                p.terminate()
            Logger.info(f"Closing {p_name}")
            try:
                p.close()
            except Exception as e:
                Logger.error(f"Failed to close {p_name} due to {e}, terminating")
                p.terminate()
        return

    def _close_queues(self, queues: dict = None):
        queues = queues or self._queues
        for q_name, q in queues.items():
            Logger.info(f"Closing {q_name}")
            q.close()
        return

    def _on_error(self, error):
        """ Gracefully close all child processes and queues and raise error """
        self._close_queues()
        self._close_processes()
        raise error

    def detect(self, stream, threshold, threshold_type, trig_int, plot=False,
               plotdir=None, daylong=False, parallel_process=True,
               xcorr_func=None, concurrency=None, cores=None,
               concurrent_processing=True, ignore_length=False,
               ignore_bad_data=False, group_size=None, overlap="calculate",
               full_peaks=False, save_progress=False, process_cores=None,
               pre_processed=False, check_processing=True,
               **kwargs):
        """
        Detect using a Tribe of templates within a continuous stream.

        :type stream: `JoinableQueue` or `obspy.core.stream.Stream`
        :param stream:
            Queue of streams of continuous data to detect within using the
            Templates, or just the continuous data itself.
        :type threshold: float
        :param threshold:
            Threshold level, if using `threshold_type='MAD'` then this will be
            the multiple of the median absolute deviation.
        :type threshold_type: str
        :param threshold_type:
            The type of threshold to be used, can be MAD, absolute or
            av_chan_corr.  See Note on thresholding below.
        :type trig_int: float
        :param trig_int:
            Minimum gap between detections from one template in seconds.
            If multiple detections occur within trig_int of one-another, the
            one with the highest cross-correlation sum will be selected.
        :type plot: bool
        :param plot: Turn plotting on or off.
        :type plotdir: str
        :param plotdir:
            The path to save plots to. If `plotdir=None` (default) then the
            figure will be shown on screen.
        :type daylong: bool
        :param daylong:
            Set to True to use the
            :func:`eqcorrscan.utils.pre_processing.dayproc` routine, which
            preforms additional checks and is more efficient for day-long data
            over other methods.
        :type parallel_process: bool
        :param parallel_process:
        :type xcorr_func: str or callable
        :param xcorr_func:
            A str of a registered xcorr function or a callable for implementing
            a custom xcorr function. For more information see:
            :func:`eqcorrscan.utils.correlate.register_array_xcorr`
        :type concurrency: str
        :param concurrency:
            The type of concurrency to apply to the xcorr function. Options are
            'multithread', 'multiprocess', 'concurrent'. For more details see
            :func:`eqcorrscan.utils.correlate.get_stream_xcorr`
        :type cores: int
        :param cores: Number of workers for processing and detection.
        :type concurrent_processing: bool
        :param concurrent_processing:
            Whether to process steps in detection workflow concurrently or not.
        :type ignore_length: bool
        :param ignore_length:
            If using daylong=True, then dayproc will try check that the data
            are there for at least 80% of the day, if you don't want this check
            (which will raise an error if too much data are missing) then set
            ignore_length=True.  This is not recommended!
        :type ignore_bad_data: bool
        :param ignore_bad_data:
            If False (default), errors will be raised if data are excessively
            gappy or are mostly zeros. If True then no error will be raised,
            but an empty trace will be returned (and not used in detection).
        :type group_size: int
        :param group_size:
            Maximum number of templates to run at once, use to reduce memory
            consumption, if unset will use all templates.
        :type overlap: float
        :param overlap:
            Either None, "calculate" or a float of number of seconds to
            overlap detection streams by.  This is to counter the effects of
            the delay-and-stack in calculating cross-correlation sums. Setting
            overlap = "calculate" will work out the appropriate overlap based
            on the maximum lags within templates.
        :type full_peaks: bool
        :param full_peaks: See `eqcorrscan.utils.findpeak.find_peaks2_short`
        :type save_progress: bool
        :param save_progress:
            Whether to save the resulting party at every data step or not.
            Useful for long-running processes.
        :type process_cores: int
        :param process_cores:
            Number of processes to use for pre-processing (if different to
            `cores`).
        :type pre_processed: bool
        :param pre_processed:
            Whether the stream has been pre-processed or not to match the
            templates.
        :type check_processing: bool
        :param check_processing:
            Whether to check that all templates were processed the same.
        :type return_stream: bool
        :param return_stream: Whether to return the stream or not.

        :return:
            :class:`eqcorrscan.core.match_filter.Party` of Families of
            detections.

        .. Note::
            When using the "fftw" correlation backend the length of the fft
            can be set. See :mod:`eqcorrscan.utils.correlate` for more info.

        .. Note::
            `stream` must not be pre-processed. If your data contain gaps
            you should *NOT* fill those gaps before using this method.
            The pre-process functions (called within) will fill the gaps
            internally prior to processing, process the data, then re-fill
            the gaps with zeros to ensure correlations are not incorrectly
            calculated within gaps. If your data have gaps you should pass a
            merged stream without the `fill_value` argument
            (e.g.: `stream = stream.merge()`).

        .. note::
            **Data overlap:**

            Internally this routine shifts and trims the data according to the
            offsets in the template (e.g. if trace 2 starts 2 seconds after
            trace 1 in the template then the continuous data will be shifted
            by 2 seconds to align peak correlations prior to summing).
            Because of this, detections at the start and end of continuous
            data streams **may be missed**.  The maximum time-period that
            might be missing detections is the maximum offset in the template.

            To work around this, if you are conducting matched-filter
            detections through long-duration continuous data, we suggest
            using some overlap (a few seconds, on the order of the maximum
            offset in the templates) in the continuous data.  You will then
            need to post-process the detections (which should be done anyway
            to remove duplicates).  See below note for how `overlap` argument
            affects data internally if `stream` is longer than the processing
            length.

        .. Note::
            If `stream` is longer than processing length, this routine will
            ensure that data overlap between loops, which will lead to no
            missed detections at data start-stop points (see above note).
            This will result in end-time not being strictly
            honoured, so detections may occur after the end-time set.  This is
            because data must be run in the correct process-length.

        .. note::
            **Thresholding:**

            **MAD** threshold is calculated as the:

            .. math::

                threshold {\\times} (median(abs(cccsum)))

            where :math:`cccsum` is the cross-correlation sum for a given
            template.

            **absolute** threshold is a true absolute threshold based on the
            cccsum value.

            **av_chan_corr** is based on the mean values of single-channel
            cross-correlations assuming all data are present as required for
            the template, e.g:

            .. math::

                av\_chan\_corr\_thresh=threshold \\times (cccsum /
                len(template))

            where :math:`template` is a single template from the input and the
            length is the number of channels within this template.
        """
        # We should not need to copy the stream, it is copied in
        # chunks by _group_process
        # Argument handling
        if overlap is None:
            overlap = 0.0
        elif not isinstance(overlap, float) and str(overlap) == "calculate":
            overlap = max(
                _moveout(template.st) for template in self.templates)
        elif not isinstance(overlap, float):
            raise NotImplementedError(
                "%s is not a recognised overlap type" % str(overlap))
        assert overlap < self.templates[0].process_length, (
            f"Overlap {overlap} must be less than process length "
            f"{self.templates[0].process_length}")

        # Copy because we need to muck around with them.
        inner_kwargs = copy.copy(kwargs)

        plot_format = inner_kwargs.pop("plot_format", "png")
        export_cccsums = inner_kwargs.pop('export_cccsums', False)
        peak_cores = inner_kwargs.pop('peak_cores',
                                      process_cores) or cpu_count()
        if peak_cores == 1:
            parallel = False
        else:
            parallel = True

        if check_processing:
            assert len(quick_group_templates(self.templates)) == 1, (
                "Inconsistent template processing parameters found, this is no"
                " longer supported. Split your tribe using "
                "eqcorrscan.core.match_filter.template.quick_group_templates "
                "and re-run for each group")
        sampling_rate = self.templates[0].samp_rate
        # Used for sanity checking seed id overlap
        template_ids = set(
            tr.id for template in self.templates for tr in template.st)

        args = (stream, template_ids, pre_processed, parallel_process,
                process_cores, daylong, ignore_length, overlap, ignore_bad_data,
                group_size, sampling_rate, threshold, threshold_type,
                save_progress, xcorr_func, concurrency, cores, export_cccsums,
                parallel, peak_cores, trig_int, full_peaks, plot, plotdir,
                plot_format,)

        if concurrent_processing:
            party = self._detect_concurrent(*args, **inner_kwargs)
        else:
            party = self._detect_serial(*args, **inner_kwargs)

        Logger.info("Ensuring all templates are in party")
        additional_families = []
        for template in self.templates:
            if template.name in party._template_dict.keys():
                continue
            additional_families.append(
                Family(template=template, detections=[]))
        party.families.extend(additional_families)

        # Post-process
        if len(party) > 0:
            Logger.info("Removing duplicates")
            party = _remove_duplicates(party)
        return party

    def _detect_serial(
        self, stream, template_ids, pre_processed, parallel_process,
        process_cores, daylong, ignore_length, overlap, ignore_bad_data,
        group_size, sampling_rate, threshold, threshold_type, save_progress,
        xcorr_func, concurrency, cores, export_cccsums, parallel, peak_cores,
        trig_int, full_peaks, plot, plotdir, plot_format,
        **kwargs
    ):
        """ Internal serial detect workflow. """
        party = Party()

        st_chunks = _pre_process(
            st=stream, template_ids=template_ids, pre_processed=pre_processed,
            filt_order=self.templates[0].filt_order,
            highcut=self.templates[0].highcut,
            lowcut=self.templates[0].lowcut,
            samp_rate=self.templates[0].samp_rate,
            process_length=self.templates[0].process_length,
            parallel=parallel_process, cores=process_cores, daylong=daylong,
            ignore_length=ignore_length, ignore_bad_data=ignore_bad_data,
            overlap=overlap, **kwargs)

        chunk_files = []
        for st_chunk in st_chunks:
            starttime = st_chunk[0].stats.starttime
            delta = st_chunk[0].stats.delta
            template_groups = _group(
                sids={tr.id for tr in st_chunk},
                templates=self.templates, group_size=group_size)
            for i, template_group in enumerate(template_groups):
                templates = [_quick_copy_stream(t.st) for t in template_group]
                template_names = [t.name for t in template_group]
                Logger.info(
                    f"Prepping {len(templates)} templates for correlation")

                # We need to copy the stream here.
                _st, templates, template_names = _prep_data_for_correlation(
                    stream=_quick_copy_stream(st_chunk), templates=templates,
                    template_names=template_names)

                all_peaks, thresholds, no_chans, chans = _corr_and_peaks(
                    templates=templates, template_names=template_names,
                    stream=_st, xcorr_func=xcorr_func, concurrency=concurrency,
                    cores=cores, i=i, export_cccsums=export_cccsums,
                    parallel=parallel, peak_cores=peak_cores,
                    threshold=threshold, threshold_type=threshold_type,
                    trig_int=trig_int, sampling_rate=sampling_rate,
                    full_peaks=full_peaks, plot=plot, plotdir=plotdir,
                    plot_format=plot_format, prepped=False, **kwargs)

                detections = _detect(
                    template_names=template_names,
                    all_peaks=all_peaks, starttime=starttime,
                    delta=delta, no_chans=no_chans,
                    chans=chans, thresholds=thresholds)

                chunk_file = _make_party(
                    detections=detections, threshold=threshold,
                    threshold_type=threshold_type,
                    templates=self.templates, chunk_start=starttime,
                    chunk_id=i, save_progress=save_progress)
                chunk_files.append(chunk_file)
        # Rebuild
        for _chunk_file in chunk_files:
            Logger.info(f"Adding party from {_chunk_file} to party")
            with open(_chunk_file, "rb") as _f:
                party += pickle.load(_f)
            if not save_progress:
                os.remove(_chunk_file)
            Logger.info(f"Added party from {_chunk_file}, party now "
                        f"contains {len(party)} detections")

        return party

    def _detect_concurrent(
        self, stream, template_ids, pre_processed, parallel_process,
        process_cores, daylong, ignore_length, overlap, ignore_bad_data,
        group_size, sampling_rate, threshold, threshold_type, save_progress,
        xcorr_func, concurrency, cores, export_cccsums, parallel, peak_cores,
        trig_int, full_peaks, plot, plotdir, plot_format,
        **kwargs
    ):
        """ Internal concurrent detect workflow. """
        party = Party()

        stream_input = None
        if isinstance(stream, Stream):
            stream_input = stream
            st_queue = JoinableQueue(maxsize=2)
            st_queue.put(stream)
            # Close off queues
            st_queue.put(None)

            stream = st_queue
            Logger.info(stream)

        # Set up processes and queues
        poison_queue = kwargs.get('poison_queue', JoinableQueue())

        if not pre_processed:
            grouping_sid_queue = JoinableQueue(maxsize=1)
            processed_stream_queue = JoinableQueue(maxsize=1)
        else:
            if stream_input is None:
                try:
                    grouping_sid_queue = kwargs["grouping_sid_queue"]
                except KeyError:
                    raise NotImplementedError(
                        "If passing a queue of pre-processed streams you must "
                        "also pass a grouping_sid_queue of seed ids in the "
                        "streams")
            else:
                grouping_sid_queue = JoinableQueue(maxsize=2)
                grouping_sid_queue.put({tr.id for tr in stream_input})
                grouping_sid_queue.put(None)
            processed_stream_queue = stream

        # Templates queue cannot have a max size - grouping goes big
        templates_queue = JoinableQueue()
        # Prepped queue contains templates and stream (and extras)
        prepped_queue = JoinableQueue(maxsize=1)
        # Output queues
        peaks_queue = JoinableQueue()
        detection_queue = JoinableQueue()
        party_file_queue = JoinableQueue()
        party_queue = JoinableQueue()

        # Set up processes
        if not pre_processed:
            pre_processor_process = Process(
                target=_pre_processor,
                kwargs=dict(
                    stream_queue=stream,
                    template_ids=template_ids,
                    pre_processed=pre_processed,
                    filt_order=self.templates[0].filt_order,
                    highcut=self.templates[0].highcut,
                    lowcut=self.templates[0].lowcut,
                    samp_rate=self.templates[0].samp_rate,
                    process_length=self.templates[0].process_length,
                    parallel=parallel_process,
                    cores=process_cores,
                    daylong=daylong,
                    ignore_length=ignore_length,
                    overlap=overlap,
                    ignore_bad_data=ignore_bad_data,
                    output_queue=processed_stream_queue,
                    output_sid_queue=grouping_sid_queue,
                    poison_queue=poison_queue,
                ),
                name="PreProcess"
            )
        grouping_process = Process(
            target=_grouping_processor,
            kwargs=dict(
                sid_queue=grouping_sid_queue,  # Input queue
                templates_queue=templates_queue,  # Output queue
                templates=self.templates,
                group_size=group_size,
                poison_queue=poison_queue,
            ),
            name="Grouper"
        )
        prepper_process = Process(
            target=_prepper,
            kwargs=dict(
                input_stream_queue=processed_stream_queue,
                input_templates_queue=templates_queue,
                output_queue=prepped_queue,
                poison_queue=poison_queue,
                xcorr_func=xcorr_func,
            ),
            name="Prepper"
        )
        detector_process = Process(
            target=_make_detections,
            kwargs=dict(
                input_queue=peaks_queue,
                delta=1 / sampling_rate,
                output_queue=detection_queue,
                poison_queue=poison_queue,
            ),
            name="Detector"
        )
        detection_builder_process = Process(
            target=_detections_to_party,
            kwargs=dict(
                input_queue=detection_queue,
                templates=self.templates,
                threshold=threshold,
                threshold_type=threshold_type,
                save_progress=save_progress,
                output_queue=party_file_queue,
                poison_queue=poison_queue,
            ),
            name="DetectBuilder"
        )
        party_builder_process = Process(
            target=_reconstruct_party,
            kwargs=dict(
                input_queue=party_file_queue,
                output_queue=party_queue,
                poison_queue=poison_queue,
                clean=~save_progress,
            ),
            name="PartyBuilder"
        )

        # Cope with old tribes
        if not hasattr(self, '_processes'):
            self._processes = dict()
        if not hasattr(self, '_queues'):
            self._queues = dict()

        # Put these processes into the namespace
        self._processes.update({
            "grouper": grouping_process,
            "prepper": prepper_process,
            "detector": detector_process,
            "detection-builder": detection_builder_process,
            "party_builder": party_builder_process,
        })
        self._queues.update({
            "poison": poison_queue,
            "stream": stream,
            "grouping_sids": grouping_sid_queue,
            "templates": templates_queue,
            "prepped": prepped_queue,
            "peaks": peaks_queue,
            "detections": detection_queue,
            "party_file": party_file_queue,
            "party": party_queue,
        })

        if not pre_processed:
            Logger.info("Starting preprocessor")
            self._processes.update({"pre-processor": pre_processor_process})
            self._queues.update({"processed_stream": processed_stream_queue})
            pre_processor_process.start()
            Logger.info(pre_processor_process)

        # Start your engines!
        grouping_process.start()
        prepper_process.start()
        detector_process.start()
        detection_builder_process.start()
        party_builder_process.start()

        # Loop over input streams and template groups
        while True:
            killed = _check_for_poison(poison_queue)
            if killed:
                break
            try:
                to_corr = prepped_queue.get()
                if to_corr is None:
                    Logger.info("Ran out of streams, exiting correlation")
                    break
                starttime, i, stream, template_names, templates,\
                    *extras = to_corr
                inner_kwargs = copy.copy(kwargs)  # We will mess around with them
                # Correlation specific handling to reduce single-threaded time
                if xcorr_func == "fmf":
                    # (starttime, d_arr, template_names, t_arr, weights, pads, chans, no_chans)
                    weights, pads, chans, no_chans = extras
                    inner_kwargs.update({
                        'weights': weights, 'pads': pads, "no_chans": no_chans,
                        "chans": chans, "prepped": True})
                elif xcorr_func in (None, 'fftw'):
                    pads, seed_ids = extras
                    inner_kwargs.update({
                        "pads": pads, "seed_ids": seed_ids, "prepped": True})

                Logger.info(f"Got stream of {len(stream)} channels")
                Logger.info(f"Starting correlation from {starttime}")

                all_peaks, thresholds, no_chans, chans = _corr_and_peaks(
                    templates=templates, template_names=template_names,
                    stream=stream, xcorr_func=xcorr_func,
                    concurrency=concurrency,
                    cores=cores, i=i, export_cccsums=export_cccsums,
                    parallel=parallel, peak_cores=peak_cores,
                    threshold=threshold, threshold_type=threshold_type,
                    trig_int=trig_int, sampling_rate=sampling_rate,
                    full_peaks=full_peaks, plot=plot, plotdir=plotdir,
                    plot_format=plot_format, **inner_kwargs
                )
                peaks_queue.put(
                    (starttime, all_peaks, thresholds, no_chans, chans,
                     template_names))
            except Exception as e:
                Logger.error(
                    f"Caught exception in correlator:\n {e}")
                traceback.print_tb(e.__traceback__)
                poison_queue.put(e)
                break  # We need to break in Main
            i += 1
        Logger.debug("Putting None into peaks queue.")
        peaks_queue.put(None)

        # Get the party back
        Logger.info("Waiting for party")
        while True:
            killed = _check_for_poison(poison_queue)
            if killed:
                Logger.error("Killed")
                break
            try:
                party = party_queue.get_nowait()
            except Empty:
                time.sleep(0.1)  # Give some time for syncs
                continue
            # Once we get the party we are free to go
            break

        # Check for exceptions
        if killed:
            internal_error = poison_queue.get()
            Logger.error(f"Raising error {internal_error} in main process")
            # Now we can raise the error
            if internal_error:
                self._on_error(internal_error)

        # Shut down the processes and close the queues
        shutdown = kwargs.get("shutdown", True)
        # Allow client_detect to take control
        if shutdown:
            Logger.info("Shutting down")
            self._close_queues()
            self._close_processes()
        return party

    def client_detect(self, client, starttime, endtime, threshold,
                      threshold_type, trig_int, plot=False, plotdir=None,
                      min_gap=None, daylong=False, parallel_process=True,
                      xcorr_func=None, concurrency=None, cores=None,
                      concurrent_processing=True, ignore_length=False,
                      ignore_bad_data=False, group_size=None,
                      return_stream=False, full_peaks=False,
                      save_progress=False, process_cores=None, retries=3,
                      check_processing=True, **kwargs):
        """
        Detect using a Tribe of templates within a continuous stream.

        :type client: `obspy.clients.*.Client`
        :param client: Any obspy client with a dataselect service.
        :type starttime: :class:`obspy.core.UTCDateTime`
        :param starttime: Start-time for detections.
        :type endtime: :class:`obspy.core.UTCDateTime`
        :param endtime: End-time for detections
        :type threshold: float
        :param threshold:
            Threshold level, if using `threshold_type='MAD'` then this will be
            the multiple of the median absolute deviation.
        :type threshold_type: str
        :param threshold_type:
            The type of threshold to be used, can be MAD, absolute or
            av_chan_corr.  See Note on thresholding below.
        :type trig_int: float
        :param trig_int:
            Minimum gap between detections from one template in seconds.
            If multiple detections occur within trig_int of one-another, the
            one with the highest cross-correlation sum will be selected.
        :type plot: bool
        :param plot: Turn plotting on or off.
        :type plotdir: str
        :param plotdir:
            The path to save plots to. If `plotdir=None` (default) then the
            figure will be shown on screen.
        :type min_gap: float
        :param min_gap:
            Minimum gap allowed in data - use to remove traces with known
            issues
        :type daylong: bool
        :param daylong:
            Set to True to use the
            :func:`eqcorrscan.utils.pre_processing.dayproc` routine, which
            preforms additional checks and is more efficient for day-long data
            over other methods.
        :type parallel_process: bool
        :param parallel_process:
        :type xcorr_func: str or callable
        :param xcorr_func:
            A str of a registered xcorr function or a callable for implementing
            a custom xcorr function. For more information see:
            :func:`eqcorrscan.utils.correlate.register_array_xcorr`
        :type concurrency: str
        :param concurrency:
            The type of concurrency to apply to the xcorr function. Options are
            'multithread', 'multiprocess', 'concurrent'. For more details see
            :func:`eqcorrscan.utils.correlate.get_stream_xcorr`
        :type cores: int
        :param cores: Number of workers for processing and detection.
        :type concurrent_processing: bool
        :param concurrent_processing:
            Whether to process steps in detection workflow concurrently or not.
        :type ignore_length: bool
        :param ignore_length:
            If using daylong=True, then dayproc will try check that the data
            are there for at least 80% of the day, if you don't want this check
            (which will raise an error if too much data are missing) then set
            ignore_length=True.  This is not recommended!
        :type ignore_bad_data: bool
        :param ignore_bad_data:
            If False (default), errors will be raised if data are excessively
            gappy or are mostly zeros. If True then no error will be raised,
            but an empty trace will be returned (and not used in detection).
        :type group_size: int
        :param group_size:
            Maximum number of templates to run at once, use to reduce memory
            consumption, if unset will use all templates.
        :type full_peaks: bool
        :param full_peaks: See `eqcorrscan.utils.findpeaks.find_peaks2_short`
        :type save_progress: bool
        :param save_progress:
            Whether to save the resulting party at every data step or not.
            Useful for long-running processes.
        :type process_cores: int
        :param process_cores:
            Number of processes to use for pre-processing (if different to
            `cores`).
        :type return_stream: bool
        :param return_stream:
            Whether to also output the stream downloaded, useful if you plan
            to use the stream for something else, e.g. lag_calc.
        :type retries: int
        :param retries:
            Number of attempts allowed for downloading - allows for transient
            server issues.

        :return:
            :class:`eqcorrscan.core.match_filter.Party` of Families of
            detections.


        .. Note::
            When using the "fftw" correlation backend the length of the fft
            can be set. See :mod:`eqcorrscan.utils.correlate` for more info.

        .. Note::
            Ensures that data overlap between loops, which will lead to no
            missed detections at data start-stop points (see note for
            :meth:`eqcorrscan.core.match_filter.Tribe.detect` method).
            This will result in end-time not being strictly
            honoured, so detections may occur after the end-time set.  This is
            because data must be run in the correct process-length.

        .. warning::
            Plotting within the match-filter routine uses the Agg backend
            with interactive plotting turned off.  This is because the function
            is designed to work in bulk.  If you wish to turn interactive
            plotting on you must import matplotlib in your script first,
            when you then import match_filter you will get the warning that
            this call to matplotlib has no effect, which will mean that
            match_filter has not changed the plotting behaviour.

        .. note::
            **Thresholding:**

            **MAD** threshold is calculated as the:

            .. math::

                threshold {\\times} (median(abs(cccsum)))

            where :math:`cccsum` is the cross-correlation sum for a given
            template.

            **absolute** threshold is a true absolute threshold based on the
            cccsum value.

            **av_chan_corr** is based on the mean values of single-channel
            cross-correlations assuming all data are present as required for
            the template, e.g:

            .. math::

                av\_chan\_corr\_thresh=threshold \\times (cccsum /
                len(template))

            where :math:`template` is a single template from the input and the
            length is the number of channels within this template.
        """
        # This uses get_waveforms_bulk to get data - not all client types have
        # this, so we check and monkey patch here.
        if not hasattr(client, "get_waveforms_bulk"):
            assert hasattr(client, "get_waveforms"), (
                f"client {client} must have at least a get_waveforms method")
            Logger.info(f"Client {client} does not have a get_waveforms_bulk "
                        "method, monkey-patching this")
            client = get_waveform_client(client)

        if check_processing:
            assert len(quick_group_templates(self.templates)) == 1, (
                "Inconsistent template processing parameters found, this is no"
                " longer supported. Split your tribe using "
                "eqcorrscan.core.match_filter.template.quick_group_templates "
                "and re-run for each group")

        buff = 300
        # Apply a buffer, often data downloaded is not the correct length
        data_length = max([t.process_length for t in self.templates])
        pad = 0
        for template in self.templates:
            max_delay = (template.st.sort(['starttime'])[-1].stats.starttime -
                         template.st.sort(['starttime'])[0].stats.starttime)
            if max_delay > pad:
                pad = max_delay
        download_groups = int(endtime - starttime) / data_length

        full_stream_file = None
        if return_stream:
            full_stream_file = tempfile.NamedTemporaryFile().name
        if int(download_groups) < download_groups:
            download_groups = int(download_groups) + 1
        else:
            download_groups = int(download_groups)

        # Get data in advance
        time_queue = JoinableQueue()
        poison_queue = JoinableQueue()
        stream_queue = JoinableQueue(maxsize=1)
        sid_queue = JoinableQueue(maxsize=1)

        detector_kwargs = dict(
            threshold=threshold, threshold_type=threshold_type,
            trig_int=trig_int, plot=plot, plotdir=plotdir,
            daylong=daylong, parallel_process=parallel_process,
            xcorr_func=xcorr_func, concurrency=concurrency, cores=cores,
            ignore_length=ignore_length, ignore_bad_data=ignore_bad_data,
            group_size=group_size, overlap=None, full_peaks=full_peaks,
            process_cores=process_cores, save_progress=save_progress,
            return_stream=return_stream, check_processing=False,
            poison_queue=poison_queue, shutdown=False, pre_processed=True,
            concurrent_processing=concurrent_processing)

        downloader = Process(
            target=_get_detection_stream,
            kwargs=dict(
                time_queue=time_queue,
                client=client,
                retries=retries,
                min_gap=min_gap,
                buff=buff,
                out_sid_queue=sid_queue,
                out_queue=stream_queue,
                poison_queue=poison_queue,
                full_stream_file=full_stream_file,
                pre_process=True, parallel_process=parallel_process,
                process_cores=process_cores, daylong=daylong,
                overlap=0.0, ignore_length=ignore_length,
                ignore_bad_data=ignore_bad_data,
                filt_order=self.templates[0].filt_order,
                highcut=self.templates[0].highcut,
                lowcut=self.templates[0].lowcut,
                samp_rate=self.templates[0].samp_rate,
                process_length=self.templates[0].process_length,
                template_channel_ids=self._template_channel_ids(),
            ),
            name="Downloader"
        )

        # Cope with old tribes
        if not hasattr(self, '_processes'):
            self._processes = dict()
        if not hasattr(self, '_queues'):
            self._queues = dict()
        # Put processes and queues into shared state
        self._processes.update({
            "downloader": downloader,
        })
        self._queues.update({
            "times": time_queue,
            "poison": poison_queue,
            "stream": stream_queue,
        })

        # Fill time queue
        for i in range(download_groups):
            time_queue.put((starttime + (i * data_length) - pad,
                            starttime + ((i + 1) * data_length) + pad))
        # Close off queue
        time_queue.put(None)

        # Start up processes
        downloader.start()

        # Catch errors
        if concurrent_processing:
            party = self.detect(
                stream=stream_queue, grouping_sid_queue=sid_queue,
                **detector_kwargs)
        else:
            # We have to get the stream here
            party = Party()
            while True:
                st = stream_queue.get()
                try:
                    _sids = sid_queue.get_nowait()
                    # We don't need this, be we have to empty it
                except Empty:
                    pass
                if st is None:
                    Logger.info("Ran out of streams")
                    break
                party += self.detect(stream=st, **detector_kwargs)

        # Close and join processes
        self._close_processes()
        self._close_queues()

        if return_stream:
            full_st = read(full_stream_file)
            os.remove(full_stream_file)
            return party, full_st
        return party

    def construct(self, method, lowcut, highcut, samp_rate, filt_order,
                  length, prepick, swin="all", process_len=86400,
                  all_horiz=False, delayed=True, plot=False, plotdir=None,
                  min_snr=None, parallel=False, num_cores=False,
                  skip_short_chans=False, save_progress=False, **kwargs):
        """
        Generate a Tribe of Templates.

        :type method: str
        :param method:
            Method of Tribe generation. Possible options are: `from_client`,
            `from_meta_file`.  See below on the additional required arguments
            for each method.
        :type lowcut: float
        :param lowcut:
            Low cut (Hz), if set to None will not apply a lowcut
        :type highcut: float
        :param highcut:
            High cut (Hz), if set to None will not apply a highcut.
        :type samp_rate: float
        :param samp_rate:
            New sampling rate in Hz.
        :type filt_order: int
        :param filt_order:
            Filter level (number of corners).
        :type length: float
        :param length: Length of template waveform in seconds.
        :type prepick: float
        :param prepick: Pre-pick time in seconds
        :type swin: str
        :param swin:
            P, S, P_all, S_all or all, defaults to all: see note in
            :func:`eqcorrscan.core.template_gen.template_gen`
        :type process_len: int
        :param process_len: Length of data in seconds to download and process.
        :type all_horiz: bool
        :param all_horiz:
            To use both horizontal channels even if there is only a pick on
            one of them.  Defaults to False.
        :type delayed: bool
        :param delayed: If True, each channel will begin relative to it's own
            pick-time, if set to False, each channel will begin at the same
            time.
        :type plot: bool
        :param plot: Plot templates or not.
        :type plotdir: str
        :param plotdir:
            The path to save plots to. If `plotdir=None` (default) then the
            figure will be shown on screen.
        :type min_snr: float
        :param min_snr:
            Minimum signal-to-noise ratio for a channel to be included in the
            template, where signal-to-noise ratio is calculated as the ratio
            of the maximum amplitude in the template window to the rms
            amplitude in the whole window given.
        :type parallel: bool
        :param parallel: Whether to process data in parallel or not.
        :type num_cores: int
        :param num_cores:
            Number of cores to try and use, if False and parallel=True,
            will use either all your cores, or as many traces as in the data
            (whichever is smaller).
        :type save_progress: bool
        :param save_progress:
            Whether to save the resulting template set at every data step or
            not. Useful for long-running processes.
        :type skip_short_chans: bool
        :param skip_short_chans:
            Whether to ignore channels that have insufficient length data or
            not. Useful when the quality of data is not known, e.g. when
            downloading old, possibly triggered data from a datacentre

        .. note::
            *Method specific arguments:*

            - `from_client` requires:
                :param str client_id:
                    string passable by obspy to generate Client, or any object
                    with a `get_waveforms` method, including a Client instance.
                :param `obspy.core.event.Catalog` catalog:
                    Catalog of events to generate template for
                :param float data_pad: Pad length for data-downloads in seconds
            - `from_meta_file` requires:
                :param str meta_file:
                    Path to obspy-readable event file, or an obspy Catalog
                :param `obspy.core.stream.Stream` st:
                    Stream containing waveform data for template. Note that
                    this should be the same length of stream as you will use
                    for the continuous detection, e.g. if you detect in
                    day-long files, give this a day-long file!
                :param bool process:
                    Whether to process the data or not, defaults to True.

        .. Note::
            Method: `from_sac` is not supported by Tribe.construct and must
            use Template.construct.

        .. Note:: Templates will be named according to their start-time.
        """
        templates, catalog, process_lengths = template_gen.template_gen(
            method=method, lowcut=lowcut, highcut=highcut, length=length,
            filt_order=filt_order, samp_rate=samp_rate, prepick=prepick,
            return_event=True, save_progress=save_progress, swin=swin,
            process_len=process_len, all_horiz=all_horiz, plotdir=plotdir,
            delayed=delayed, plot=plot, min_snr=min_snr, parallel=parallel,
            num_cores=num_cores, skip_short_chans=skip_short_chans,
            **kwargs)
        for template, event, process_len in zip(templates, catalog,
                                                process_lengths):
            t = Template()
            # Template-gen already does this check, no need to duplicate
            # for tr in template:
            #     if not np.any(tr.data.astype(np.float16)):
            #         Logger.warning('Data are zero in float16, missing data,'
            #                        ' will not use: {0}'.format(tr.id))
            #         template.remove(tr)
            if len(template) == 0:
                Logger.error('Empty Template')
                continue
            t.st = template
            t.name = template.sort(['starttime'])[0]. \
                stats.starttime.strftime('%Y_%m_%dt%H_%M_%S')
            t.lowcut = lowcut
            t.highcut = highcut
            t.filt_order = filt_order
            t.samp_rate = samp_rate
            t.process_length = process_len
            t.prepick = prepick
            event.comments.append(Comment(
                text="eqcorrscan_template_" + t.name,
                creation_info=CreationInfo(agency='eqcorrscan',
                                           author=getpass.getuser())))
            t.event = event
            self.templates.append(t)
        return self

    def _template_channel_ids(self, wildcards: bool = False):
        template_channel_ids = set()
        for template in self.templates:
            for tr in template.st:
                # Cope with missing info and convert to wildcards
                n, s, l, c = tr.id.split('.')
                if wildcards:
                    if n in [None, '']:
                        n = "*"
                    if s in [None, '']:
                        s = "*"
                    if l in [None, '']:
                        l = "*"
                    if c in [None, '']:
                        c = "*"
                    # Cope with old seisan chans
                    if len(c) == 2:
                        c = f"{c[0]}?{c[-1]}"
                template_channel_ids.add((n, s, l, c))
        return template_channel_ids


###############################################################################
#                                  Helpers
###############################################################################

def _remove_duplicates(party: Party) -> Party:
    for family in party:
        if family is not None:
            # Slow uniq:
            # family.detections = family._uniq().detections
            # Very quick uniq:
            det_tuples = [
                (det.id, str(det.detect_time), det.detect_val)
                for det in family]
            # Retrieve the indices for the first occurrence of each
            # detection in the family (so only unique detections will
            # remain).
            uniq_det_tuples, uniq_det_indices = np.unique(
                det_tuples, return_index=True, axis=0)
            uniq_detections = []
            for uniq_det_index in uniq_det_indices:
                uniq_detections.append(family[uniq_det_index])
            family.detections = uniq_detections
    return party


def _moveout(st: Stream) -> float:
    """ Maximum moveout across template in seconds. """
    return max(tr.stats.starttime for tr in st) - min(
        tr.stats.starttime for tr in st)


def _mad(cccsum):
    """
    Internal helper to compute MAD-thresholds in parallel.
    """
    return np.median(np.abs(cccsum))


###############################################################################
#                               Detect steps
###############################################################################

# TODO: Move these to matched_filter to make it easier to work on all the parts
def _pre_process(
    st, template_ids, pre_processed, filt_order, highcut, lowcut, samp_rate,
    process_length, parallel, cores, daylong, ignore_length, ignore_bad_data,
    overlap, **kwargs
):
    # Retain only channels that have matches in templates
    Logger.info(template_ids)
    st = Stream([tr for tr in st if tr.id in template_ids])
    Logger.info(f"Processing {(len(st))} channels")
    if len(st) == 0:
        raise IndexError(
            "No matching channels between stream and templates")
    tic = default_timer()
    _spike_test(st)
    toc = default_timer()
    Logger.info(f"Checking for spikes took {toc - tic:.4f} s")
    if not pre_processed:
        st_chunks = _group_process(
            filt_order=filt_order,
            highcut=highcut,
            lowcut=lowcut,
            samp_rate=samp_rate,
            process_length=process_length,
            parallel=parallel,
            cores=cores,
            stream=st,
            daylong=daylong,
            ignore_length=ignore_length,
            overlap=overlap,
            ignore_bad_data=ignore_bad_data)
    else:
        st_chunks = [st]
    Logger.info(f"Stream has been split into {len(st_chunks)} chunks")
    return st_chunks


def _group(sids, templates, group_size):
    Logger.info(f"Grouping for {sids}")
    # Do the grouping
    if group_size is not None:
        template_groups = group_templates_by_seedid(
            templates=templates,
            st_seed_ids=sids,
            group_size=group_size)
    else:
        template_groups = [templates]
    return template_groups


def _corr_and_peaks(
    templates, template_names, stream, xcorr_func, concurrency, cores, i,
    export_cccsums, parallel, peak_cores, threshold, threshold_type,
    trig_int, sampling_rate, full_peaks, plot, plotdir, plot_format,
    prepped=False, **kwargs
):
    # Special cases for fmf and fftw to minimize reshaping time.
    Logger.info(
        f"Starting correlation run for template group {i}")
    tic = default_timer()
    if prepped and xcorr_func == "fmf":
        assert isinstance(templates, np.ndarray)
        assert isinstance(stream, np.ndarray)
        # These need to be passed from queues.
        pads = kwargs.get('pads')
        weights = kwargs.get('weights')
        chans = kwargs.get("chans")
        no_chans = kwargs.get("no_chans")
        # We do not care about removing the gain from our data, we copied it.
        multipliers = np.ones((len(stream), 1))
        step = 1  # We only implement single-step correlations
        if concurrency in ("multithread", "multiprocess"):
            arch = "cpu"
        else:
            arch = "gpu"
        cccsums = _stabalised_fmf(
            template_arr=templates, data_arr=stream, weights=weights,
            pads=pads, arch=arch, multipliers=multipliers, step=step)
    elif prepped and xcorr_func in ("fftw", None):
        assert isinstance(templates, dict)
        assert isinstance(stream, dict)
        pads = kwargs.pop('pads')
        seed_ids = kwargs.pop("seed_ids")
        num_cores_inner, num_cores_outer = _set_inner_outer_threading(
            kwargs.get('cores', None), kwargs.get("cores_outer", None),
            len(stream))

        cccsums, tr_chans = fftw_multi_normxcorr(
            template_array=templates, stream_array=stream,
            pad_array=pads, seed_ids=seed_ids, cores_inner=num_cores_inner,
            cores_outer=num_cores_outer, stack=True, **kwargs)
        n_templates = len(cccsums)
        # Post processing
        no_chans = np.sum(np.array(tr_chans).astype(int), axis=0)
        chans = [[] for _i in range(n_templates)]
        for seed_id, tr_chan in zip(seed_ids, tr_chans):
            for chan, state in zip(chans, tr_chan):
                if state:
                    chan.append(seed_id)
        cccsums = _zero_invalid_correlation_sums(cccsums, pads, chans)
        chans = [[(seed_id.split('.')[1], seed_id.split('.')[-1].split('_')[0])
                  for seed_id in _chans] for _chans in chans]
    else:
        # The default just uses stream xcorr funcs.
        multichannel_normxcorr = get_stream_xcorr(xcorr_func, concurrency)
        cccsums, no_chans, chans = multichannel_normxcorr(
            templates=templates, stream=stream, cores=cores, **kwargs
        )
    if len(cccsums[0]) == 0:
        raise MatchFilterError(
            f"Correlation has not run for group {i}, "
            f"zero length cccsum")
    toc = default_timer()
    Logger.info(
        f"Correlations for group {i} of {len(templates)} "
        f"templates took {toc - tic:.4f} s")
    Logger.debug(
        f"The shape of the returned cccsums in group {i} "
        f"is: {cccsums.shape}")
    Logger.debug(
        f'This is from {len(templates)} templates correlated with '
        f'{len(stream)} channels of data in group {i}')

    # Handle saving correlation stats
    if export_cccsums:
        for i, cccsum in enumerate(cccsums):
            fname = (
                f"{template_names[i]}-{stream[0].stats.starttime}-"
                f"{stream[0].stats.endtime}_cccsum.npy")
            np.save(file=fname, arr=cccsum)
            Logger.info(
                f"Saved correlation statistic to {fname}")

    # Zero mean check
    if np.any(np.abs(cccsums.mean(axis=-1)) > 0.05):
        Logger.warning(
            'Mean of correlations is non-zero!  Check this!')
    if parallel:
        Logger.info(f"Finding peaks using {peak_cores} threads")
    else:
        Logger.info("Finding peaks in serial")
    # This is in the main process because transferring
    #  lots of large correlation sums in queues is very slow
    all_peaks, thresholds = _threshold(
        cccsums=cccsums, no_chans=no_chans,
        template_names=template_names, threshold=threshold,
        threshold_type=threshold_type,
        trig_int=int(trig_int * sampling_rate),
        parallel=parallel, full_peaks=full_peaks,
        peak_cores=peak_cores, plot=plot, stream=stream,
        plotdir=plotdir, plot_format=plot_format)
    return all_peaks, thresholds, no_chans, chans


def _threshold(
    cccsums: np.ndarray,
    no_chans: list,
    template_names: list,
    threshold: float,
    threshold_type: str,
    trig_int: int,  # converted to samples before getting to this func.
    parallel: bool,
    full_peaks: bool,
    peak_cores: int,
    plot: bool,
    stream: Stream,
    plotdir: str,
    plot_format: str,
):
    Logger.debug(f"Got cccsums shaped {cccsums.shape}")
    Logger.debug(f"From {len(template_names)} templates")

    tic = default_timer()
    if str(threshold_type) == str("absolute"):
        thresholds = [threshold for _ in range(len(cccsums))]
    elif str(threshold_type) == str('MAD'):
        median_cores = min([peak_cores, len(cccsums)])
        if cccsums.size < 2e7:  # par not worth it
            median_cores = 1
        with ThreadPoolExecutor(max_workers=median_cores) as executor:
            # Because numpy releases GIL threading can use
            # multiple cores
            medians = executor.map(_mad, cccsums,
                                   chunksize=len(cccsums) // median_cores)
        thresholds = [threshold * median for median in medians]
    else:
        thresholds = [threshold * no_chans[i]
                      for i in range(len(cccsums))]
    toc = default_timer()
    Logger.info(f"Computing thresholds took {toc - tic: .4f} s")
    outtic = default_timer()
    all_peaks = multi_find_peaks(
        arr=cccsums, thresh=thresholds, parallel=parallel,
        trig_int=trig_int, full_peaks=full_peaks, cores=peak_cores)
    outtoc = default_timer()
    Logger.info(f"Finding peaks for group took {outtoc - outtic:.4f}s")

    # Plotting
    if plot and stream:
        for i, cccsum in enumerate(cccsums):
            _match_filter_plot(
                stream=stream, cccsum=cccsum,
                template_names=template_names,
                rawthresh=thresholds[i], plotdir=plotdir,
                plot_format=plot_format, i=i)
        else:
            Logger.error("Plotting enabled but not stream found to plot")

    # output_queue.put(
    #     (starttime, all_peaks, thresholds, no_chans, chans,
    #      template_names))
    return all_peaks, thresholds


def _detect(
    template_names, all_peaks, starttime, delta, no_chans, chans, thresholds):
    tic = default_timer()
    detections = []
    for i, template_name in enumerate(template_names):
        if not all_peaks[i]:
            Logger.debug(f"Found 0 peaks for template {template_name}")
            continue
        Logger.debug(f"Found {len(all_peaks[i])} detections "
                     f"for template {template_name}")
        for peak in all_peaks[i]:
            detecttime = starttime + (peak[1] * delta)
            if peak[0] > no_chans[i]:
                Logger.error(f"Correlation sum {peak[0]} exceeds "
                             f"bounds ({no_chans[i]}")
            detection = Detection(
                template_name=template_name, detect_time=detecttime,
                no_chans=no_chans[i], detect_val=peak[0],
                threshold=thresholds[i], typeofdet='corr',
                chans=chans[i],
                threshold_type=None,
                # Update threshold_type and threshold outside of this func.
                threshold_input=None)
            detections.append(detection)
    toc = default_timer()
    Logger.info(f"Forming detections took {toc - tic:.4f} s")
    return detections


def _make_party(
        detections, threshold, threshold_type, templates, chunk_start,
        chunk_id, save_progress
):
    chunk_dir = ".parties/{chunk_start.year}/{chunk_start.julday:03d}"
    chunk_file_str = os.path.join(
        chunk_dir, "chunk_party_{chunk_start}_{chunk_id}.pkl")

    # Get the results out of the end!
    Logger.info(f"Made {len(detections)} detections")

    # post - add in threshold, threshold_type to all detections
    Logger.info("Adding threshold to detections")
    for detection in detections:
        detection.threshold_input = threshold
        detection.threshold_type = threshold_type

    # Select detections very quickly: detection order does not
    # change, make dict of keys: template-names and values:
    # list of indices and use indices to select
    Logger.info("Making dict of detections")
    detection_idx_dict = defaultdict(list)
    for n, detection in enumerate(detections):
        detection_idx_dict[detection.template_name].append(n)

    # Convert to Families and build party.
    Logger.info("Converting to party and making events")
    chunk_party = Party()
    for template in templates:
        family_detections = [
            detections[idx]
            for idx in detection_idx_dict[template.name]]
        for d in family_detections:
            d._calculate_event(template=template)
        # Make party sparse - only write out families with detections
        if len(family_detections):
            family = Family(
                template=template, detections=family_detections)
            chunk_party += family

    Logger.info("Pickling party")
    if not os.path.isdir(chunk_dir.format(chunk_start=chunk_start)):
        os.makedirs(chunk_dir.format(chunk_start=chunk_start))

    chunk_file = chunk_file_str.format(
        chunk_start=chunk_start, chunk_id=chunk_id)
    with open(chunk_file, "wb") as _f:
        pickle.dump(chunk_party, _f)
    Logger.info("Completed party processing")

    if save_progress:
        Logger.info(f"Written chunk to {chunk_file}")
    return chunk_file

###############################################################################
#                           Process handlers
###############################################################################


def _check_for_poison(poison_queue: JoinableQueue) -> bool:
    """
    Check if poison has been added to the queue.
    """
    Logger.debug("Checking for poison")
    try:
        poison = poison_queue.get_nowait()
    except Empty:
        return False
    # Put the poison back in the queue for another process to check on
    Logger.error("Poisoned")
    poison_queue.put(poison)
    return True


def _get_detection_stream(
    template_channel_ids: List[tuple],
    client,
    time_queue: JoinableQueue,
    retries: int,
    min_gap: float,
    buff: float,
    out_queue: JoinableQueue,
    out_sid_queue: JoinableQueue,
    poison_queue: JoinableQueue,
    full_stream_file: bool = None,
    pre_process: bool = False,
    parallel_process: bool = True,
    process_cores: int = None,
    daylong: bool = False,
    overlap: Union[str, float] = "calculate",
    ignore_length: bool = False,
    ignore_bad_data: bool = False,
    filt_order: int = None,
    highcut: float = None,
    lowcut: float = None,
    samp_rate: float = None,
    process_length: float = None
):
    from obspy.clients.fdsn.client import FDSNException

    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        try:
            next_times = time_queue.get()
            if next_times is None:
                break
            starttime, endtime = next_times
            bulk_info = []
            for chan_id in template_channel_ids:
                bulk_info.append((
                    chan_id[0], chan_id[1], chan_id[2], chan_id[3],
                    starttime - buff, endtime + buff))

            for retry_attempt in range(retries):
                try:
                    Logger.info(f"Downloading data between {starttime} and "
                                f"{endtime}")
                    st = client.get_waveforms_bulk(bulk_info)
                    Logger.info(
                        "Downloaded data for {0} traces".format(len(st)))
                    break
                except FDSNException as e:
                    if "Split the request in smaller" in " ".join(e.args):
                        Logger.warning(
                            "Datacentre does not support large requests: "
                            "splitting request into smaller chunks")
                        st = Stream()
                        for _bulk in bulk_info:
                            try:
                                st += client.get_waveforms_bulk([_bulk])
                            except Exception as e:
                                Logger.error("No data for {0}".format(_bulk))
                                Logger.error(e)
                                continue
                        Logger.info("Downloaded data for {0} traces".format(
                            len(st)))
                        break
                except Exception as e:
                    Logger.error(e)
                    continue
            else:
                raise MatchFilterError(
                    "Could not download data after {0} attempts".format(
                        retries))
            # Get gaps and remove traces as necessary
            if min_gap:
                gaps = st.get_gaps(min_gap=min_gap)
                if len(gaps) > 0:
                    Logger.warning("Large gaps in downloaded data")
                    st.merge()
                    gappy_channels = list(
                        set([(gap[0], gap[1], gap[2], gap[3])
                             for gap in gaps]))
                    _st = Stream()
                    for tr in st:
                        tr_stats = (tr.stats.network, tr.stats.station,
                                    tr.stats.location, tr.stats.channel)
                        if tr_stats in gappy_channels:
                            Logger.warning(
                                "Removing gappy channel: {0}".format(tr))
                        else:
                            _st += tr
                    st = _st
                    st.split()
            st.detrend("simple").merge()
            st.trim(starttime=starttime, endtime=endtime)
            for tr in st:
                if not _check_daylong(tr.data):
                    st.remove(tr)
                    Logger.warning(
                        "{0} contains more zeros than non-zero, "
                        "removed".format(tr.id))
            for tr in st:
                if tr.stats.endtime - tr.stats.starttime < \
                        0.8 * (endtime - starttime):
                    st.remove(tr)
                    Logger.warning(
                        "{0} is less than 80% of the required length"
                        ", removed".format(tr.id))
            if len(st) == 0:
                Logger.warning(f"No suitable data between {starttime} "
                               f"and {endtime}, skipping")
                continue
            if pre_process:
                template_ids = set(['.'.join(sid)
                                    for sid in template_channel_ids])
                st_chunks = _pre_process(
                    st=st, template_ids=template_ids, pre_processed=False,
                    filt_order=filt_order, highcut=highcut,
                    lowcut=lowcut, samp_rate=samp_rate,
                    process_length=process_length,
                    parallel=parallel_process, cores=process_cores,
                    daylong=daylong, ignore_length=ignore_length,
                    overlap=overlap, ignore_bad_data=ignore_bad_data)
                for chunk in st_chunks:
                    out_sid_queue.put({tr.id for tr in chunk})
                    out_queue.put(chunk)
            else:
                out_sid_queue.put({tr.id for tr in st})
                out_queue.put(st)
            if full_stream_file:
                # Open in append mode - we can just add more records to mseed
                with open(full_stream_file, "ab") as _f:
                    st.write(_f, format="MSEED")
        except Exception as e:
            Logger.error(f"Caught exception {e} in downloader")
            poison_queue.put(e)
            break
    out_queue.put(None)
    return


def _pre_processor(
    stream_queue: JoinableQueue,
    template_ids: set,
    pre_processed: bool,
    filt_order: int,
    highcut: float,
    lowcut: float,
    samp_rate: float,
    process_length: float,
    parallel: bool,
    cores: int,
    daylong: bool,
    ignore_length: bool,
    overlap: float,
    ignore_bad_data: bool,
    output_queue: JoinableQueue,
    output_sid_queue: JoinableQueue,
    poison_queue: JoinableQueue
):
    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        Logger.debug("Getting stream from queue")
        st = stream_queue.get()
        if st is None:
            Logger.info("Ran out of streams, stopping processing")
            break
        if len(st) == 0:
            break
        Logger.info(f"Processing stream:\n{st}")

        # 1. Process stream
        try:
            st_chunks = _pre_process(
                st, template_ids, pre_processed, filt_order, highcut, lowcut,
                samp_rate, process_length, parallel, cores, daylong,
                ignore_length, ignore_bad_data, overlap)
            for chunk in st_chunks:
                output_sid_queue.put({tr.id for tr in chunk})
                output_queue.put(chunk)
        except Exception as e:
            Logger.error(
                    f"Caught exception in processor:\n {e}")
            poison_queue.put(e)
            traceback.print_tb(e.__traceback__)
    output_queue.put(None)
    return


def _grouping_processor(
    sid_queue: JoinableQueue,
    templates_queue: JoinableQueue,
    group_size: int,
    templates: List,
    poison_queue: JoinableQueue,
):
    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        Logger.debug("Getting sids from queue")
        sids = sid_queue.get()
        if sids is None:
            Logger.info("Ran out of streams for grouping, stopping grouper")
            break
        Logger.info(f"Got {sids}")
        try:
            template_groups = _group(sids=sids, templates=templates,
                                     group_size=group_size)
            # Put template groups into the queue - we need to do the copy here.
            Logger.info(f"Grouped into {len(template_groups)} groups")
            for template_group in template_groups:
                templates_queue.put(
                    [(t.name, _quick_copy_stream(t.st))
                     for t in template_group])
            Logger.info("Put templates into queue")
            templates_queue.put(None)
        except Exception as e:
            Logger.error(
                    f"Caught exception in grouper:\n {e}")
            traceback.print_tb(e.__traceback__)
            poison_queue.put(e)
    templates_queue.put(None)  # close off the queue
    return


def _prepper(
    input_stream_queue: JoinableQueue,
    input_templates_queue: JoinableQueue,
    output_queue: JoinableQueue,
    poison_queue: JoinableQueue,
    xcorr_func: str = None,
):
    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        Logger.info("Getting stream from queue")
        st = input_stream_queue.get()
        if st is None:
            Logger.info("Got None for stream, prepper complete")
            break
        i = 0  # Template group id
        while True:
            killed = _check_for_poison(poison_queue)
            if killed:
                break
            try:
                template_group = input_templates_queue.get()
                if template_group is None:
                    break
                template_names, templates = zip(*template_group)
                Logger.info(
                    f"Prepping {len(templates)} templates for correlation")

                # We need to copy the stream here.
                _st, templates, template_names = _prep_data_for_correlation(
                    stream=_quick_copy_stream(st), templates=templates,
                    template_names=template_names)
                starttime = _st[0].stats.starttime

                if xcorr_func in (None, "fmf", "fftw"):
                    array_dict_tuple = _get_array_dicts(
                        templates, _st, stack=True)
                    stream_dict, template_dict, pad_dict, \
                        seed_ids = array_dict_tuple
                    if xcorr_func == "fmf":
                        # Work out used channels here
                        tr_chans = np.array(
                            [~np.isnan(template_dict[seed_id]).any(axis=1)
                             for seed_id in seed_ids])
                        no_chans = np.sum(np.array(tr_chans).astype(int),
                                          axis=0)
                        chans = [[] for _i in range(len(templates))]
                        for seed_id, tr_chan in zip(seed_ids, tr_chans):
                            for chan, state in zip(chans, tr_chan):
                                if state:
                                    chan.append((seed_id.split('.')[1],
                                                 seed_id.split('.')[-1].split(
                                                     '_')[0]))
                        # Reshape
                        t_arr, d_arr, weights, pads = _fmf_reshape(
                            template_dict=template_dict,
                            stream_dict=stream_dict,
                            pad_dict=pad_dict, seed_ids=seed_ids)
                        # Stabilise
                        t_arr, d_arr, multipliers = _fmf_stabilisation(
                            template_arr=t_arr, data_arr=d_arr)
                        # Put into queue
                        output_queue.put(
                            (starttime, i, d_arr, template_names, t_arr, weights,
                             pads, chans, no_chans))
                    else:
                        output_queue.put((
                            starttime, i, stream_dict, template_names,
                            template_dict, pad_dict, seed_ids))
                else:
                    output_queue.put(
                        (starttime, i, _st, template_names, templates))
            except Exception as e:
                Logger.error(f"Caught exception in Prepper: {e}")
                traceback.print_tb(e.__traceback__)
                poison_queue.put(e)
            i += 1
    output_queue.put(None)
    return


def _make_detections(
    input_queue: JoinableQueue,
    delta: float,
    output_queue: JoinableQueue,
    poison_queue: JoinableQueue,
):
    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        try:
            next_item = input_queue.get()
            if next_item is None:
                Logger.info("_make_detections got None, stopping")
                break
            starttime, all_peaks, thresholds, no_chans, \
                chans, template_names = next_item
            detections = _detect(
                template_names=template_names, all_peaks=all_peaks,
                starttime=starttime, delta=delta, no_chans=no_chans,
                chans=chans, thresholds=thresholds)
            toc = default_timer()
            output_queue.put((starttime, detections))
            Logger.info(f"Putting detections into queue "
                        f"took {default_timer() - toc:.4f} s")
        except Exception as e:
            Logger.error(
                f"Caught exception in detector:\n {e}")
            traceback.print_tb(e.__traceback__)
            poison_queue.put(e)
    output_queue.put(None)
    return


def _detections_to_party(
    input_queue: JoinableQueue,
    templates: List,
    threshold: float,
    threshold_type: str,
    save_progress: bool,
    output_queue: JoinableQueue,
    poison_queue: JoinableQueue,
):
    chunk_id, _chunk_files = 0, []

    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        try:
            detections = input_queue.get()
            if detections is None:
                break
            chunk_start, detections = detections
            chunk_file = _make_party(
                detections=detections, threshold=threshold,
                threshold_type=threshold_type, templates=templates,
                chunk_start=chunk_start, chunk_id=chunk_id,
                save_progress=save_progress)
            chunk_id += 1
            _chunk_files.append(chunk_file)
            output_queue.put(chunk_file)
        except Exception as e:
            Logger.error(f"Caught exception in detection to party: {e}")
            traceback.print_tb(e.__traceback__)
            poison_queue.put(e)

    output_queue.put(None)
    return


def _reconstruct_party(
    input_queue: JoinableQueue,
    output_queue: JoinableQueue,
    poison_queue: JoinableQueue,
    clean: bool = True,
):
    party = Party()
    while True:
        killed = _check_for_poison(poison_queue)
        if killed:
            break
        try:
            _chunk_file = input_queue.get()
            if _chunk_file is None:
                break
            Logger.info(f"Adding party from {_chunk_file} to party")
            with open(_chunk_file, "rb") as _f:
                party += pickle.load(_f)
            if clean:
                os.remove(_chunk_file)
            Logger.info(f"Added party from {_chunk_file}, party now "
                        f"contains {len(party)} detections")
        except Exception as e:
            Logger.error(f"Caught exception in party reconstructer {e}")
            traceback.print_tb(e.__traceback__)
            poison_queue.put(e)
    output_queue.put(party)
    output_queue.put(None)
    return


def read_tribe(fname):
    """
    Read a Tribe of templates from a tar archive.

    :param fname: Filename to read from
    :return: :class:`eqcorrscan.core.match_filter.Tribe`
    """
    tribe = Tribe()
    tribe.read(filename=fname)
    return tribe


if __name__ == "__main__":
    import doctest

    doctest.testmod()
    # List files to be removed after doctest
    cleanup = ['test_tribe.tgz']
    for f in cleanup:
        if os.path.isfile(f):
            os.remove(f)
        elif os.path.isdir(f):
            shutil.rmtree(f)
